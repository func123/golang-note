[TOC]

# 散列表

​	散列表的实现主要分为两步：

1. 通过散列函数找到key所属的bucket
2. 解决碰撞。而解决碰撞的方法有拉链法和线性探测法

# 数据结构	

```go
// A header for a Go map.
type hmap struct {
	count     int // 元素个数，调用len（map）时，返回该字段值
	flags     uint8	// 状态位
	B         uint8  // 2^B是bucket的数量, 指示map的容量
	noverflow uint16 // 溢出桶的大约值， 具体可看 incrnoverflow 方法
	hash0     uint32 // 哈希种子
	buckets    unsafe.Pointer // 指向大小为2^B的Buckets数组，当count==0时，该字段是nil
	oldbuckets unsafe.Pointer // 只有在growing时，才不为nil。大小为当前buckets的一半 
	nevacuate  uintptr        // 表示扩容时，搬迁的进度：包括该桶之前的所有桶都已完成搬迁

	extra *mapextra // optional fields
}

// flags 枚举值：
	iterator     = 1 // 一个遍历器正在使用 buckets
	oldIterator  = 2 // 一个遍历器正在使用 oldbuckets
	hashWriting  = 4 // 一个 goroutine 正在对 map 做写操作
	sameSizeGrow = 8 // map正处于等量扩容
```



```go
// 不是所有map都会有这个字段值
type mapextra struct {
	// 如果key/value都没有包含指针并且是内建类型，那么我们标记bucket为不含指针。这个能避免gc扫描整个map
	// 然而，bmap中的overflow(下一个桶,碰撞桶之间是链表结构)是一个指针。在这种情况下，就把
	// 所有溢出桶的指针保存在 hmap.extra.overflow 和 hmap.extra.oldoverflow.因此
	// hmap.extra.overflow 和 hmap.extra.oldoverflow 仅仅被用在key/value 都不包含指针的时候。
	// overflow 保存 hmap 的 buckets
	// oldoverflow 保存 hmap 的 oldbuckets
   overflow    *[]*bmap
   oldoverflow *[]*bmap

   // nextOverflow 指向一个暂未使用的溢出桶的指针 
   nextOverflow *bmap
}



// A bucket for a Go map.
type bmap struct {
	
	tophash [bucketCnt]uint8 	// tophash 通常包含的是在桶中key的哈希值的高位， 如果 tophash[0] < minTopHash
								// 那么 tophash[0] 的值 表示的是一个枚举状态，而不是key对应哈希值的高位
	// keys [8]					// 接着是数量为bucketCnt（8）的 keys 和 elems 数组.
	// elems [8]				// 虽然把 keys 和 elems 各自放在一起 比 key/elem/key/elem/...  要复杂一点，
	// overflow unsafe.Pointer	// 但是这样便于消除对齐，不用为了内存对齐而填补无用的空间									
								// e.g., map[int64]int8.
								// 最后是一个溢出bucket的指针
}

// tophash中值的对应枚举值标记
	emptyRest      = 0 // 初始状态的空值，表示该槽以及数组后面中槽都暂未被使用过
	emptyOne       = 1 // 空值（区别于emptyRest，可能曾经不为空，但是现在是空值）
	evacuatedX     = 2 // key/elem 是有效的，槽中的key/elem已经被迁移到新桶的前部分（具体看扩容逻辑）
	evacuatedY     = 3 // 跟上面一样, 但是槽中的key/elem已经被迁移到新桶的后部分
	evacuatedEmpty = 4 // 空值，并且该bucket已搬迁完成
	minTopHash     = 5 // 该值是一个key对应哈希值高位的一个最小值.该值之后都是表示key的哈希值的高位



```



# API

## 创建

主要逻辑：

1. 创建 `hamp`
2. 生成哈希种子
3. 计算 B 的大小
4. 根据 B 生成哈希桶和溢出桶，
   1. 当B=0时, `hmap.buckets = nil`，当插入时候，才进行初始化
   2. 当B≥4时，才会生成溢出桶

```go

func makemap(t *maptype, hint int, h *hmap) *hmap {
	//校验溢出
   mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size)
   if overflow || mem > maxAlloc {
      hint = 0
   }

   // 初始化hamp
   if h == nil {
      h = new(hmap)
   }
   h.hash0 = fastrand()

   // 根据hint，找到合适的 B 
   B := uint8(0)
   for overLoadFactor(hint, B) {
      B++
   }
   h.B = B

   // 初始化 hash table 
   // 如果 B==0 ,当后面执行插入操作的时候，再初始化 h.buckets
   // 如果 hint 很大，内存分配会花费一些时间
   if h.B != 0 {
      var nextOverflow *bmap
      h.buckets, nextOverflow = makeBucketArray(t, h.B, nil)
      if nextOverflow != nil {
         h.extra = new(mapextra)
         h.extra.nextOverflow = nextOverflow
      }
   }

   return h
}

// 判断 B 是否太小
func overLoadFactor(count int, B uint8) bool {
    // count > 8 && uintptr(count) > 6.5 * 2^B
	return count > bucketCnt && uintptr(count) > loadFactorNum*(bucketShift(B)/loadFactorDen)
}


// makeBucketArray 为 map 初始化 buckets array.
// 最少会分配 1<<b 个 buckets
// dirtyalloc 只能是 nil 或者是 以前被 makeBucketArray 用一样的 t 和 b 参数分配的 buckets array
// 如果 dirtyalloc 是nil, 那么将会分配新的数组将
// 否则 dirtyalloc 将会被清除后做为新的数组被复用
func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) {
	base := bucketShift(b)  // 1<<b
	nbuckets := base
	// 对于小于4的B（8），没必要预先分配溢出桶，另一方面也可以节约计算的开销
	if b >= 4 {
		// 计算溢出桶数组的内存大小，把经过padding，对齐后的内存大小除于 t.bucket.size 
        // 得到实际的溢出桶数量
		nbuckets += bucketShift(b - 4)
		sz := t.bucket.size * nbuckets
		up := roundupsize(sz)
		if up != sz {
			nbuckets = up / t.bucket.size
		}
	}

	if dirtyalloc == nil {
		buckets = newarray(t.bucket, int(nbuckets))
	} else {
		// dirtyalloc was previously generated by
		// the above newarray(t.bucket, int(nbuckets))
		// but may not be empty.
		buckets = dirtyalloc
		size := t.bucket.size * nbuckets
		if t.bucket.ptrdata != 0 {
			memclrHasPointers(buckets, size)
		} else {
			memclrNoHeapPointers(buckets, size)
		}
	}

	if base != nbuckets {
		// 预分配溢出桶
        // 如果一个预分配的溢出桶的 overflow 指针（关联的下一个桶）为nil，那么就表示还有更多
       	// 待使用的溢出桶。
        // 除开最后一个溢出桶的overflow字段不是nil，其他未使用的溢出桶该字段都是nil。
        // 这让我们能够持续跟踪溢出桶，但是却只要花很少的开销
		nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize)))
		last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize)))
		last.setoverflow(t, (*bmap)(buckets))
	}
	return buckets, nextOverflow
}


```

## 查找

主要逻辑：

1. 计算key的哈希值，通过该哈希值计算key处于的桶
2. 如果`hashmap`处于扩容状态且该key对应扩容前的桶还没完成搬迁，则 需要遍历的目标桶 为扩容前的桶，否则取第一步中计算的桶
3. 用哈希值的高位计算tophash，来定位槽中的位置
4. 遍历目标桶以及溢出桶，判断tophash是否相等且对应的key相等，存在则返回对应的value，否则返回0值





```go
func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	
    ·······
 	// 计算key的哈希值
	alg := t.key.alg
	hash := alg.hash(key, uintptr(h.hash0))
	// 通过 哈希值与 1<<B -1 相与，计算桶位置
	m := bucketMask(h.B)
	b := (*bmap)(add(h.buckets, (hash&m)*uintptr(t.bucketsize)))
  
	if c := h.oldbuckets; c != nil {
        // hashmap 处于扩容状态
		if !h.sameSizeGrow() {
            // 扩容前的B 等于 当前的B -1，计算扩容前的m，再计算扩容前的桶位置
			m >>= 1
		}
		oldb := (*bmap)(add(c, (hash&m)*uintptr(t.bucketsize)))
        // 如果还未搬迁，就在旧桶中遍历寻找key
		if !evacuated(oldb) {
            // 通过判断tophash的枚举状态值，可得知该桶是否完成搬迁
			b = oldb
		}
	}
    // 取哈希值的高8位作为，key的tophash
	top := tophash(hash)
bucketloop:
    // 遍历哈希桶以及后续的溢出桶
	for ; b != nil; b = b.overflow(t) {
        // 遍历桶中的槽位
		for i := uintptr(0); i < bucketCnt; i++ {
			if b.tophash[i] != top {
				if b.tophash[i] == emptyRest {
                    // 表示该槽后面都是从未使用过的空值，所以可以break了
					break bucketloop
				}
				continue
			}
            // 找到对应的key
            // dataOffset 是 对齐后的 bmap结构体大小
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			if t.indirectkey() {
                // 解引用，通过指针取得key值
				k = *((*unsafe.Pointer)(k))
			}
            // 前面判断的查找是基于哈希值，这里需要再根据key值对比下
			if alg.equal(key, k) {
                // keys 和 values 是分开扎堆放的
				e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))
				if t.indirectelem() {
					e = *((*unsafe.Pointer)(e))
				}
                // 返回 value
				return e
			}
		}
	}
   	// 返回 0 值
	return unsafe.Pointer(&zeroVal[0])
}
```



## 插入

主要逻辑：

1. 扩容状态下，进行桶搬迁
2. 遍历`bucket` 和对应的 ` overflow bucket`，先预占遍历开始后的第一个空位，随后开始查找`key`是否存在，不存在则把key/value插入到之前预占的空位
3. 非扩容状态下，判断是否触发扩容，触发扩容后重新定位和遍历bucket
4. 遍历所有桶后如果没能预占空位，则关联一个新的溢出桶，将key放在新建的溢出桶上
5. map的元素数量加1，返回bucket中对应value的指针，后续可操作指针来插入对应的value



```go
// 像查找一样, 但是会为不存在的key分配一个槽位
func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer {
	
    ······
    // 校验并发写入
	if h.flags&hashWriting != 0 {
		throw("concurrent map writes")
	}
	alg := t.key.alg
	hash := alg.hash(key, uintptr(h.hash0))

	// 因为散列函数可能发生panic，在那时还没有真正完成写入，所以在其后更改状态
	h.flags ^= hashWriting
	// 当创建容量为0的map时，对应的 h.buckets 为nil，在这里才被初始化
	if h.buckets == nil {
		h.buckets = newobject(t.bucket) // newarray(t.bucket, 1)
	}

again:
    // 得到所在的bucket（这里是hash的低 B-1 位决定bucket）
	bucket := hash & bucketMask(h.B)
     // 扩容状态下，进行桶搬迁
	if h.growing() {
        // 详细见 “搬迁” 逻辑
		growWork(t, h, bucket)
	}
    // 定位bucket位置
	b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize)))
    // 用hash高八位，计算槽位的值
	top := tophash(hash)
	// 用来预占的字段
	var inserti *uint8 // 指针，指向槽位的值
	var insertk unsafe.Pointer
	var elem unsafe.Pointer
bucketloop:
	for {
        // 遍历桶中的槽位
		for i := uintptr(0); i < bucketCnt; i++ {
			if b.tophash[i] != top {
                // 如果该槽位为空且还未预占一个槽位，则预占该槽位
				if isEmpty(b.tophash[i]) && inserti == nil {
					inserti = &b.tophash[i]
					insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
					elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))
				}
                // 该枚举值表示后续的槽位都是空的，因此这里break
				if b.tophash[i] == emptyRest {
					break bucketloop
				}
				continue
			}
            // 槽位的值与key的top相等，定位对应的key
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			if t.indirectkey() {
                // 存的是指针则解引用
				k = *((*unsafe.Pointer)(k))
			}
            // 比较key
			if !alg.equal(key, k) {
				continue
			}
			// already have a mapping for key. Update it.
			if t.needkeyupdate() {
				typedmemmove(t.key, k, key)
			}
            // 定位value，拿到elem的指针就可以修改改值，所以返回指针也能达到后续修改的目的
			elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))
            // 返回elem，退出方法
			goto done
		}
        // 继续遍历后续的溢出桶
		ovf := b.overflow(t)
		if ovf == nil {
			break
		}
		b = ovf
	}

	// key不存在，就新增槽位存放key

	// 在不是扩容状态下，如果超过了容量阈值或者有太多的溢出桶导致桶中元素过于稀疏就触发扩容
	// 详细见 “触发扩容” 逻辑
	if !h.growing() && (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {
		hashGrow(t, h)
		goto again // 触发扩容后，开始使用新桶并会在之后把旧桶数据搬迁过去。为在新桶插入该key，方法需要从新执行一次
	}
	
    // 没有预占到空槽位，表示当前桶以及溢出桶中的数据都已满，因此需要新增溢出桶
	if inserti == nil {
        // 返回一个新的溢出桶
		newb := h.newoverflow(t, b)
        // 预占溢出桶的第一个槽位
		inserti = &newb.tophash[0]
		insertk = add(unsafe.Pointer(newb), dataOffset)
		elem = add(insertk, bucketCnt*uintptr(t.keysize))
	}

	// 保存key/value到插入的位置中
	if t.indirectkey() {
		kmem := newobject(t.key)
		*(*unsafe.Pointer)(insertk) = kmem
		insertk = kmem
	}
	if t.indirectelem() {
		vmem := newobject(t.elem)
		*(*unsafe.Pointer)(elem) = vmem
	}
	typedmemmove(t.key, insertk, key)
    // 保存key的槽位置到槽位中
	*inserti = top
    // map的元素数量+1
	h.count++

done:
    // 校验写入状态
	if h.flags&hashWriting == 0 {
		throw("concurrent map writes")
	}
    // 清空 写标志位
	h.flags &^= hashWriting
	if t.indirectelem() {
		elem = *((*unsafe.Pointer)(elem))
	}
    // 返回elem指针，后续可修改key对应的valu值
	return elem
}
```





## 删除

主要逻辑：

1. 扩容状态下，进行桶搬迁
2. 定位key所在的bucket，遍历该bucket以及溢出桶，找到对应的key后删除
3. 当key被删除后，对应槽位A的值修改为 `emptyOne`，
   1. 如果后续槽位为`emptyRest`，则要把A槽位的值也修改成 `emptyRest`（表示该槽以及后面包括溢出桶的槽位都是空的）
   2. 基于完成1的修正后，从当前桶的槽位A逐个槽位往前将槽位值为`emptyOne`的修改为`emptyRest`，遇到不是`emptyOne`的就返回
4. map元素数量-1



```go
func mapdelete(t *maptype, h *hmap, key unsafe.Pointer) {
	
    ······
    
	if h == nil || h.count == 0 {
		if t.hashMightPanic() {
			t.key.alg.hash(key, 0) // see issue 23734
		}
		return
	}
    // 校验并发写
	if h.flags&hashWriting != 0 {
		throw("concurrent map writes")
	}

	alg := t.key.alg
	hash := alg.hash(key, uintptr(h.hash0))

	// 哈希函数也许会 panic,在那种情况下，实际上还未进行去修改map。
    // 所以把map的写标志放在哈希函数之后
	h.flags ^= hashWriting
	 
    //  定位 bucket 位置
	bucket := hash & bucketMask(h.B)
    // 扩容状态下，进行桶搬迁
	if h.growing() {
		growWork(t, h, bucket)
	}
    // 定位 bucket
	b := (*bmap)(add(h.buckets, bucket*uintptr(t.bucketsize)))
    // 保存遍历的第一个桶，方便后面实现槽位值的更新
	bOrig := b
	top := tophash(hash)
search:
    // 遍历bucket以及后续的溢出桶
	for ; b != nil; b = b.overflow(t) {
        // 遍历槽位
		for i := uintptr(0); i < bucketCnt; i++ {
			if b.tophash[i] != top {
                // 后续槽位以及溢出桶都为空，无须继续遍历，所以break
				if b.tophash[i] == emptyRest {
					break search
				}
				continue
			}
            // 查找命中
			k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize))
			k2 := k
			if t.indirectkey() {
				k2 = *((*unsafe.Pointer)(k2))
			}
            // 比较 key 是否相等
			if !alg.equal(key, k2) {
				continue
			}
            // 删除key/value
			// Only clear key if there are pointers in it.
			if t.indirectkey() {
				*(*unsafe.Pointer)(k) = nil
			} else if t.key.ptrdata != 0 {
				memclrHasPointers(k, t.key.size)
			}
			e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.elemsize))
			if t.indirectelem() {
				*(*unsafe.Pointer)(e) = nil
			} else if t.elem.ptrdata != 0 {
				memclrHasPointers(e, t.elem.size)
			} else {
				memclrNoHeapPointers(e, t.elem.size)
			}
           	// 删除key后，更新槽位上的值
			b.tophash[i] = emptyOne
            // 当前槽位变成空值后，如果下个槽位值为emptyRest，就要把当前槽位以及位于当前槽位之前的值为emptyOne的连续的所有槽位都要修改成 emptyRest
            // 因为一个槽位的值为emptyRest，意味着后续的所有槽位都为emptyRest。基于这一点，需要这些处理
           	// 虽然把这段逻辑封装成一个方法比较好，但是目前在for循环里面不能内联方法
           
			if i == bucketCnt-1 {
                // 如果这是当前桶的最后一个槽位且溢出桶的第一个槽位不为空，那么当前槽位的值保持 emptyOne
				if b.overflow(t) != nil && b.overflow(t).tophash[0] != emptyRest {
					goto notLast
				}
			} else {
                // 下一个槽位不是空的，那么当前槽位的值保持 emptyOne
				if b.tophash[i+1] != emptyRest {
					goto notLast
				}
			}
           	// 该槽位之后的槽位都为空，因此当前槽位需要 修改成 emptyRest，而且需要往上遍历，把上一个值为emptyOne的槽位修改成emptyRest
            // ，直到遇到一个非空的槽位值或者到初始桶的第一个槽位
			for {
				b.tophash[i] = emptyRest
          		// 当i=0 时，取出当前桶的上一个桶，倒序遍历槽位
				if i == 0 {
                    // 如果当前桶是初始桶，那就break
					if b == bOrig {
						break 
					}
					// 倒序遍历上一个桶的槽位.
					c := b 						// c 表示当前桶
					for b = bOrig; b.overflow(t) != c; b = b.overflow(t) {  // 通过for循环，从初始桶开始往下遍历，拿到当前桶的上一个桶
					}														// 并把b指向当前桶的上一个桶
					i = bucketCnt - 1
				} else {
					i--
				}
                // 往上遍历过程中，遇到一个非空的槽位置就break
				if b.tophash[i] != emptyOne {
					break
				}
			}
		notLast:
			h.count--
			break search
		}
	}
	if h.flags&hashWriting == 0 {
			throw("concurrent map writes")
	}
	h.flags &^= hashWriting
}
```



## 遍历

- 遍历会先执行 `mapiterinit` 初始化迭代器
- 再每次调用 `mapiternext  `返回值



```go
// 迭代器
type hiter struct {
	key         unsafe.Pointer // Must be in first position.  Write nil to indicate iteration end (see cmd/internal/gc/range.go).
	elem        unsafe.Pointer // Must be in second position (see cmd/internal/gc/range.go).
	t           *maptype
	h           *hmap
	buckets     unsafe.Pointer // bucket ptr at hash_iter initialization time
	bptr        *bmap          // current bucket
	overflow    *[]*bmap       // keeps overflow buckets of hmap.buckets alive
	oldoverflow *[]*bmap       // keeps overflow buckets of hmap.oldbuckets alive
	startBucket uintptr        // bucket iteration started at
	offset      uint8          // intra-bucket offset to start from during iteration (should be big enough to hold bucketCnt-1)
	wrapped     bool           // already wrapped around from end of bucket array to beginning
	B           uint8
	i           uint8
	bucket      uintptr
	checkBucket uintptr
}


// mapiterinit 初始化 hiter 结构体，去遍历map.
//  由 'it' 指向的 hiter 结构体 是由编译命令分配在 stack 上，或者由 reflect_mapiterinit 分配在 heap上
// Both need to have zeroed hiter since the struct contains pointers.
func mapiterinit(t *maptype, h *hmap, it *hiter) {
	······

	if h == nil || h.count == 0 {
		return
	}
	// 校验hiter结构体
	if unsafe.Sizeof(hiter{})/sys.PtrSize != 12 {
		throw("hash_iter size incorrect") // see cmd/compile/internal/gc/reflect.go
	}
	it.t = t
	it.h = h

	// grab snapshot of bucket state
    // 保存快照信息，后续遍历也可以通过对比最新状态来判断是否发生了并发
	it.B = h.B
	it.buckets = h.buckets
	if t.bucket.ptrdata == 0 {
		// Allocate the current slice and remember pointers to both current and old.
		// This preserves all relevant overflow buckets alive even if
		// the table grows and/or overflow buckets are added to the table
		// while we are iterating.
		h.createOverflow()
		it.overflow = h.extra.overflow
		it.oldoverflow = h.extra.oldoverflow
	}

	// map的遍历是无序的，这里决定遍历的起始桶 以及 起始槽位
	r := uintptr(fastrand())
	if h.B > 31-bucketCntBits {
		r += uintptr(fastrand()) << 31
	}
	it.startBucket = r & bucketMask(h.B)
	it.offset = uint8(r >> h.B & (bucketCnt - 1))

	// iterator state
	it.bucket = it.startBucket

	// Remember we have an iterator.
	// Can run concurrently with another mapiterinit().
	if old := h.flags; old&(iterator|oldIterator) != iterator|oldIterator {
		atomic.Or8(&h.flags, iterator|oldIterator)
	}

	mapiternext(it)
}



func mapiternext(it *hiter) {
    // 获得对应的 map
	h := it.h
	if raceenabled {
		callerpc := getcallerpc()
		racereadpc(unsafe.Pointer(h), callerpc, funcPC(mapiternext))
	}
    // 校验读写并发，如果在写状态就报错
	if h.flags&hashWriting != 0 {
		throw("concurrent map iteration and map write")
	}
	t := it.t
    // 获得当前遍历的bucker，初始等于 it.startBucket
	bucket := it.bucket
    // 在init中没有被赋值，因此hiter初始化后的第一次遍历都为nil
	b := it.bptr
	i := it.i
    
	checkBucket := it.checkBucket
	alg := t.key.alg

next: // 切换bucket（b==nil时，表示遍历到下一个桶了）
	if b == nil {
		if bucket == it.startBucket && it.wrapped {
			// end of iteration
			it.key = nil
			it.elem = nil
			return
		}
        // 遍历开始在正在扩容的map中
		if h.growing() && it.B == h.B {
            // 如果遍历的桶对应的oldbucket还未完成搬迁，那么我们需要去遍历对应的oldbucket，并且从中只返回应当被搬迁到当前桶的元素
			oldbucket := bucket & it.h.oldbucketmask()
            // 获得对应oldbucket，判断是否已经完成搬迁
			b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))
			if !evacuated(b) {
				checkBucket = bucket  // 暂未搬迁，标记当前遍历的bucket
			} else {
				b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize))) // 已搬迁，那么取当前遍历的bucket
				checkBucket = noCheck
			}
		} else {
            // 非扩容状态，直接取当前遍历的bucket
			b = (*bmap)(add(it.buckets, bucket*uintptr(t.bucketsize)))
			checkBucket = noCheck
		}
        // 计算下一个遍历的bucket
		bucket++
        // bucket的数量是2^B，范围从 0 ~ 2^B-1，当下一个遍历的bucket == 2^B时，则下一个应该是 bucket = 0
		if bucket == bucketShift(it.B) { 
			bucket = 0
			it.wrapped = true // 标记已经从bucket数组末尾遍历到头部
		}
		i = 0
	}
    // for循环找到值，找到后面就return了
	for ; i < bucketCnt; i++ {
        // 加上随机的偏移值后，从起始点开始遍历
		offi := (i + it.offset) & (bucketCnt - 1)
        // evacuatedEmpty表示已经搬迁过且该槽位原本就是空的，所以这个判断针对的是b是oldbucket的情况，那么可能此时b桶正被搬迁（所以问题是map在搬迁中能被遍历吗？）
		if isEmpty(b.tophash[offi]) || b.tophash[offi] == evacuatedEmpty {
			// TODO: emptyRest is hard to use here, as we start iterating
			// in the middle of a bucket. It's feasible, just tricky.
			continue
		}
		k := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.keysize))
		if t.indirectkey() {
			k = *((*unsafe.Pointer)(k))
		}
		e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+uintptr(offi)*uintptr(t.elemsize))
        // 遍历的olabucket && 不处于等量扩容：遍历开始在一个扩容的map中，并且oldbucket还没被搬迁
		if checkBucket != noCheck && !h.sameSizeGrow() {
			// 每次hash结果都一致的key：
			if t.reflexivekey() || alg.equal(k, k) {
				// 判断该槽位的值是分到当前桶还是另外一个桶（oldbucker会分裂成2个桶，只需要分配到当前桶的值）
                // 计算hash值
				hash := alg.hash(k, uintptr(h.hash0))
                // 判断是不是分配到当前桶，不是的话就continue
				if hash&bucketMask(it.B) != checkBucket {
					continue
				}
			} else {	// 两次hash结果不一致的key：
                //  k != k (NaNs),在这种情况下，hash的结果不是一致的
                // 因此需要足够一致性且足够随机的方式去把 NaNs 分到目标桶上。
				// 用tophash的低位去决定分配终点		
				// NOTE: this case is why we need two evacuate tophash
				// values, evacuatedX and evacuatedY, that differ in
				// their low bit.
                // 当前桶的最高位 不等于 tophash的最低位，就continue
                // 换句话就是 当前桶的最高位等于tophash的最低位，该值才被分配到当前桶
				if checkBucket>>(it.B-1) != uintptr(b.tophash[offi]&1) {
					continue
				}
			}
		}
        // 经过上面的处理后，到这里的都是属于分配到当前桶的key
        // 该槽位没有被搬迁（可能是当前桶的槽位也可能是oldbucket中属于当前桶但是没被搬迁的） || key不是hash一致的
		if (b.tophash[offi] != evacuatedX && b.tophash[offi] != evacuatedY) ||
			!(t.reflexivekey() || alg.equal(k, k)) {
			// This is the golden data, we can return it.
			// OR
			// key!=key, so the entry can't be deleted or updated, so we can just return it.
			// That's lucky for us because when key!=key we can't look it up successfully.
			it.key = k
			if t.indirectelem() {
				e = *((*unsafe.Pointer)(e))
			}
			it.elem = e
		} else {
			// 在遍历的时候，map扩容了，因此当前桶变成了map的oldbucket，因此在当前的map中找到对应的值
			// This code handles the case where the key
			// has been deleted, updated, or deleted and reinserted.
			// NOTE: we need to regrab the key as it has potentially been
			// updated to an equal() but not identical key (e.g. +0.0 vs -0.0).
			rk, re := mapaccessK(t, h, k)
			if rk == nil {
				continue // key has been deleted
			}
			it.key = rk
			it.elem = re
		}
        // 保存下一个遍历桶到hiter
        // 1、当前桶及其溢出桶遍历完后，b==nil且跳转到next，开始遍历下一个桶：bucket
        // 2、当前桶开始遍历下一个值时（即再次调用当前方法），拿到的bucket是下一个桶，而且通过 it.bptr
        // 能得到当前桶并在其中遍历
		it.bucket = bucket
        // b 已经变成 下一个桶，才更新it.bptr
		if it.bptr != b { // avoid unnecessary write barrier; see issue 14921
			it.bptr = b
		}
        // 保存当前遍历桶的槽位 到hiter
		it.i = i + 1
        // 只有 b==nil 的时候才会计算checkBucket
		it.checkBucket = checkBucket
		return
	}
	b = b.overflow(t)
	i = 0
	goto next
}
```





```

```









# 重要方法

## 新增溢出桶

1. 当key/value不是指针时，如果`h.extra`为空会初始化后，把新增的溢出桶保存在`h.extra.overflow`中
2. 预分配的最后一个溢出桶的`overflow`字段不为nil（预分配溢出桶时，为了跟踪溢出桶状态而做的低开销处理），因此如果用到的是最后个溢出桶，需要更新相关值



```go
func (h *hmap) newoverflow(t *maptype, b *bmap) *bmap {
	var ovf *bmap
	if h.extra != nil && h.extra.nextOverflow != nil {
		// 还有预先分配的溢出桶
		ovf = h.extra.nextOverflow
		if ovf.overflow(t) == nil { // 表示ovf不是预先分配的溢出桶的最后一个
			// 指向下一个待使用的溢出桶
			h.extra.nextOverflow = (*bmap)(add(unsafe.Pointer(ovf), uintptr(t.bucketsize)))
		} else {
			// ovf 是预分配的最后一个溢出桶，
			// 更新相关值
			ovf.setoverflow(t, nil)
			h.extra.nextOverflow = nil
		}
	} else {
        // 新增一个桶
		ovf = (*bmap)(newobject(t.bucket))
	}
    // 更新 noverflow 的值
	h.incrnoverflow()
    // 如果key/value 不含指针
	if t.bucket.ptrdata == 0 {
        // 创建并且初始化 h.extra.overflow
		h.createOverflow()
		*h.extra.overflow = append(*h.extra.overflow, ovf)
	}
    // 当前桶 引用 溢出桶，并返回溢出桶
	b.setoverflow(t, ovf)
	return ovf
}

// incrnoverflow 更新 h.noverflow 的值
// noverflow 计算溢出桶的数量，被用于计算等量扩容的触发
// 为了保持hashmap在一个小的规模，noverflow 被限定在 uint16 的数据类型
// 当只有少量的溢出桶时，noverflow 是一个精确的溢出桶数量
// 当有大量的溢出桶时, noverflow 是一个大概的溢出桶数量.
func (h *hmap) incrnoverflow() {
	// 如果有大量的溢出桶，就触发等量扩容.
	// h.noverflow 的数据类型是uint16，所以需要能够数到1<<h.B.
	if h.B < 16 {
		h.noverflow++
		return
	}
	// 按照 1/(1<<(h.B-15)) 的概率增加
	// When we reach 1<<15 - 1, we will have approximately
	// as many overflow buckets as buckets.
	mask := uint32(1)<<(h.B-15) - 1
	// Example: if h.B == 18, then mask == 7,
	// and fastrand & 7 == 0 （值可能是0~7，八种可能），这个概率是 1/8.
	if fastrand()&mask == 0 {
		h.noverflow++
	}
}
```

## 扩容条件

```go
// 当不在扩容状态下触发扩容有两个条件：1、元素数量超过了负载系数，触发增量扩容 2、溢出桶太多导致的桶稀疏，触发等量扩容
	if !h.growing() && (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {
		hashGrow(t, h)
		goto again 
	}	

// overLoadFactor， 判断在1<<B个桶中，元素数量是否超过了负载系数.
func overLoadFactor(count int, B uint8) bool {
    // 元素数量 大于 8 且  大于 6.5 * 1<<B                                      
	return count > bucketCnt && uintptr(count) > loadFactorNum*(bucketShift(B)/loadFactorDen)
}

// tooManyOverflowBuckets 判断对一个有1<<B个桶的map是否有太多的溢出桶了.
// 注意太多的溢出桶 一定会让 map 中的元素 变得稀疏;
// 如果元素太密集，我们可以触发常规的增量扩容.
func tooManyOverflowBuckets(noverflow uint16, B uint8) bool {
	// 最大值限制成15，是因为 如果 最大值 太 低，需要做额外的工作.
	// 如果最大值太高, 扩容和收缩的 maps 都会hold住大量未使用的内存.
	// "too many" 意思是 noverflow 的数量 等于 常规桶的数量（正常来说常规桶的数量为1<<b，那么溢出桶数量为1<<(b-4））
	// 可以结合 incrnoverflow 方法看更多细节
	if B > 15 {
		B = 15
	}
	// The compiler doesn't see here that B < 16; mask B to generate shorter shift code.
	return noverflow） >= uint16(1)<<(B&15)
}

```



## 触发扩容



```go
func hashGrow(t *maptype, h *hmap) {
	// 可能是增量扩容和等量扩容，先定义扩容增量.
	bigger := uint8(1)
	if !overLoadFactor(h.count+1, h.B) {
        // 等量扩容，则设置等量扩容标志，把扩容增量设置成0
		bigger = 0
		h.flags |= sameSizeGrow
	}
    // oldbuckets 指向 扩容前的buckets
	oldbuckets := h.buckets
    // 分配新的BucketArray
	newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)
	// flags 的 iterator和oldIterator标志位为0，其他位为1
	flags := h.flags &^ (iterator | oldIterator)
	if h.flags&iterator != 0 { // 有迭代器在遍历 map 的当前桶
        // 当前桶变成旧的桶了，因此标志位也要改成 有迭代器遍历map的旧桶
		flags |= oldIterator
	}
	// commit the grow (atomic wrt gc)
    // 更新相关变量
	h.B += bigger
	h.flags = flags
	h.oldbuckets = oldbuckets
	h.buckets = newbuckets
	h.nevacuate = 0
	h.noverflow = 0
	// 更新 h.extra 的相关值
    // h.extra.oldoverflow 指向扩容前溢出桶
    // 因为还没搬迁，所以h.extra.overflow 是nil
    // h.extra.nextOverflo 指向新分配的溢出桶
	if h.extra != nil && h.extra.overflow != nil {
		// Promote current overflow buckets to the old generation.
		if h.extra.oldoverflow != nil {
			throw("oldoverflow is not nil")
		}
		h.extra.oldoverflow = h.extra.overflow
		h.extra.overflow = nil
	}
	if nextOverflow != nil {
		if h.extra == nil {
			h.extra = new(mapextra)
		}
		h.extra.nextOverflow = nextOverflow
	}

	// 实际的数据转移工作是  growWork() and evacuate() 完成
	// 这里只是做一些变量的更新和初始化
}
```

## 扩容后的数据搬迁

1. 扩容状态下，插入和删除时，会调用`growWork`方法进行至多2次数据搬迁
2. `evacuate`实现搬迁逻辑

```go
func growWork(t *maptype, h *hmap, bucket uintptr) {
	// 被搬迁的桶  是 bucket 对应的旧桶
    // 首先得明白 bucket 的来源： hash 的 低 1<<B 位 ，而对应的 bucket 的 旧桶是 ： hash 的 低 1<<(B-1)位
    // 所以一个旧桶 会对应2个新桶 ：例如旧桶 11 对应两个新桶 011 和 111 
    // 当新桶是 111 ，用111 与 11（oldmask）相与，就可以得到旧桶
	evacuate(t, h, bucket&h.oldbucketmask())

	// 继续搬迁当前进度后的一个桶
	if h.growing() {
		evacuate(t, h, h.nevacuate)
	}
}


func evacuate(t *maptype, h *hmap, oldbucket uintptr) {
   	// 定位旧桶
	b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize)))
    // 扩容前的 1<<B 
	newbit := h.noldbuckets()
	if !evacuated(b) {   // 判断该桶是否已完成搬迁
         // 该桶还未搬迁
		// TODO: reuse overflow buckets instead of using new ones, if there
		// is no iterator using the old buckets.  (If !oldIterator.)

		// xy 包含 X （低）和 y（高） 两个搬迁目标桶 对于一个旧桶 11 的数据会搬迁到2个新桶：011 和 111 .
        // 需要决定旧桶 11中的元素要搬迁到 新桶011（x） 还是新桶111(y)
		var xy [2]evacDst
		x := &xy[0]
        // 定位新桶x ，他跟旧桶的排位是一样的
		x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize)))
		x.k = add(unsafe.Pointer(x.b), dataOffset)
		x.e = add(x.k, bucketCnt*uintptr(t.keysize))
		
		if !h.sameSizeGrow() {
            // 如果是增量扩容，需要搬迁到低位和高位两个新桶中，所以计算y的指针
			// Otherwise GC can see bad pointers.
			y := &xy[1]
            // 定位高位的新桶y
            // newbit = 1<<B , 11 + 100 = 111 ,就是高位的新桶y
			y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize)))
			y.k = add(unsafe.Pointer(y.b), dataOffset)
			y.e = add(y.k, bucketCnt*uintptr(t.keysize))
		}
		// 遍历搬迁b桶及其溢出桶，
		for ; b != nil; b = b.overflow(t) {
			k := add(unsafe.Pointer(b), dataOffset)
			e := add(k, bucketCnt*uintptr(t.keysize))
            // 遍历桶内的槽位，当槽位遍历完后就 遍历下一个溢出桶
			for i := 0; i < bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) {
				top := b.tophash[i]
				if isEmpty(top) {
                    // 该槽位没值，标识 是空的且完成搬迁
					b.tophash[i] = evacuatedEmpty
					continue
				}
				if top < minTopHash {
					throw("bad map state")
				}
                // 如果是指针就解引用，k2 保存 key的值，为了后面hash之后确定该值属于低位还是高位桶
				k2 := k
				if t.indirectkey() {
					k2 = *((*unsafe.Pointer)(k2))
				}
				var useY uint8
				if !h.sameSizeGrow() {
					// 计算hash值去决定搬迁的目的地 (x还是y)
					hash := t.key.alg.hash(k2, uintptr(h.hash0))
                    // 迭代器正在遍历当前桶列表 并且
					if h.flags&iterator != 0 && !t.reflexivekey() && !t.key.alg.equal(k2, k2) {
						// 如果 key != key (NaNs), 那么这种情况下的key每次hash都是不一致的. 而迭代器在遍历时是需要这种每次hash后的一致性
                        // 并且 我们搬迁的规则 也必须跟迭代器遍历时的规则保持一致。幸运的是，我们可以自己选择把这些key放在x还是y上面。
                        // 当然了，tophash 对于这类型的key 是没意义的，因为每次hash都不一样。所以这里让 tophash的低1位去决定是放到x还是y桶
						// 之后，我们在重新计算一个新的tophash作为它搬迁后的tophash值，这样在多次扩容后，这类型的key会均匀的分布在map的桶上
						useY = top & 1
						top = tophash(hash)
					} else {
                        // 例如  ，111 & 100 = 1 ，因此应该搬迁到 y 桶，而对应旧桶是 11 
						if hash&newbit != 0 {
							useY = 1
						}
					}
				}
				// 检查枚举值
				if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY {
					throw("bad evacuatedN")
				}
				// 更新旧桶的槽位置，指示该槽位搬迁到X还是Y
				b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY
                // 搬迁的目标桶
				dst := &xy[useY]                 // evacuation destination
				// dst.i初始为0，每次搬迁一个元素加一，如果等于8，则说明新桶已满，新增溢出桶
				if dst.i == bucketCnt {
					dst.b = h.newoverflow(t, dst.b)
					dst.i = 0
					dst.k = add(unsafe.Pointer(dst.b), dataOffset)
					dst.e = add(dst.k, bucketCnt*uintptr(t.keysize))
				}
				dst.b.tophash[dst.i&(bucketCnt-1)] = top // mask dst.i 作为一个优化，去避免边界检查
				if t.indirectkey() {
					*(*unsafe.Pointer)(dst.k) = k2 // 复制指针
				} else {
					typedmemmove(t.key, dst.k, k) // 复制值
				}
				if t.indirectelem() {
					*(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e)	// 复制指针
				} else { 
					typedmemmove(t.elem, dst.e, e) // 复制值
				}
				dst.i++
				// 这里的变量更新也许会让这些指针超出 key or elem arrays。
				// 但这是没有问题的，一方面我们还有个overflow指针在bucket的末尾可以防止指针越过该bucket
                // 另外一方面如果发生越过，在下一次遍历，会新增溢出桶
				dst.k = add(dst.k, uintptr(t.keysize))
				dst.e = add(dst.e, uintptr(t.elemsize))
			}
		}
		// 断开旧桶中对溢出桶的引用并且清理 key/elem to help GC.
        // 迭代器没有在遍历旧桶 并且 含指针
		if h.flags&oldIterator == 0 && t.bucket.ptrdata != 0 {
            // 定位旧桶
			b := add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))
			// 保存 b.tophash 因为需要维护搬迁的状态信息
            // 清楚tophash之后包括 key/value 和overflow 的数据
			ptr := add(b, dataOffset)
			n := uintptr(t.bucketsize) - dataOffset
			memclrHasPointers(ptr, n)
		}
	}
	// 如果 被搬迁的桶 跟 搬迁进度一样 ，那么就更新 搬迁进度 。 这里的搬迁进度的意义是表示期望搬迁的下一个桶，例如 h.nevacuate= 5 ，
    // 那么表示桶4 已经完成搬迁，桶5还未被搬迁
	if oldbucket == h.nevacuate {
        // 更新 搬迁进度
		advanceEvacuationMark(h, t, newbit)
	}
}
```



# Q&A

1. 怎么理解：`bucket`中的`key/value`不是指针时，`mepextra`中的`overflow `和` oldoverflow`数组用于保存对`overflowbucket `等的引用？

   ​	当bucket中的key/value不是指针类型且是内置数据类型时，go会把bucket的类型标记成不含指针，这样能避免gc扫描整个表，但是bucket中的overflow字段是一个指针，如果gc不再扫描bucket，那么也会忽略了overflow对溢出桶的引用，将导致溢出桶的内存被gc回收清理，所以这就需要用`mepextra`中的`overflow `和` oldoverflow`数组去存放所有的`oveflow`和`oldoverflow`来保证gc不会做错事;另一方面，当key/value是指针类型时候，就不会用到`mepextra`中的`overflow `和` oldoverflow`数组。

2. 基于问题（1），go是怎么标记一个类型的值不是指针类型？【GC】

   

3. `incrnoverflow` 计算溢出桶的数量为什么要分精确和大约地计数？

   ​	当B<16，精确计算溢出桶的数量；当B>=16，在对B计算处理后，根据结果去判断是否增加溢出桶的数量，这就好像计算硬币正反面，是概率性的；而且这种处理会随着B的增加，判断增加溢出桶的概率会越小，因此该情况下溢出桶的数量相比实际数量是大概且偏小的。
   ​	而当`noverflow >= uint16(1)<<(B&15) (其中最大B=15)`时，触发等量扩容。所以可能是基于当B很大时，触发等量扩容也会产生较大的开销的原因，故当B越大，溢出桶的数量会更偏小（实际溢出桶数量会更多，这间接增大了触发等量扩容的溢出桶阈值），越会谨慎的进行扩容。

4. float 类型可以作为 map 的 key 吗？

   ​	任何支持== 和 != 操作的类型都可以作为map的key，具体包括：布尔值、数字、字符串、指针、通道、接口类型、结构体、只包含上述类型的数组。但是有以下情况需要注意：

   - NAN != NAN , hash(NAN) != hash(NAN), 对于map的key，它们是不同的值
   - 当map的key是float类型时，会有潜在的精度问题导致key值并非期望的结果

5. map中的key为什么是无序的？

   ​	

6. map是线程安全的吗？

   ​	map不是线程安全的，每次查找、赋值、遍历、删除操作都检查map的写标志位，所以读写并发和写写并发都会导致panic。

7. 删除过程是怎么样的？（省略修改标志位操作等）

   1. 扩容状态则进行桶搬迁工作
   2. 通过hash（key）的值进行相关计算找到对应的bucket，遍历槽位对比tophash找到对应的key/value
   3. 将相应的key/value清零
   4. 维护tophash的状态信息，更新当前以及在它之前槽位tophash的值
      - 当前tophash的下一个槽位（当前桶或者溢出桶）为emptyRest，则更新为emptyRest，否则更新为emptyone 
      - 向前更新：当前槽位确定更新为emptyRest后，还需要将在其之前为emptyone 的槽位值（tophash）都更改成 emptyRest。
   5. 更新map的数量（-1）	

8. 删除过程中寻找被删除的key时，不需要遍历扩容前的桶吗？

   ​	不需要，因为删除操作开始前会判断扩容状态进行桶搬迁工作，这就会将key落在的bucket搬迁掉，保证key对应的bucket是完成搬迁的。因此，不需要再去扩容前的桶中找key

9. map的底层实现原理是怎么样的？

   ​	通过元素的key的hash值决定落入的bucket，用链表的方式解决哈希冲突，即多个落入到同一个bucket中的情况。当散列表上元素分布太密集或者太稀疏会进行相应的扩容来保证map的性能，另一方面go的map在触发扩容时只是先分配新的变量内存和初始化变量而不进行数据的迁移，在插入和删除操作中才去进行旧桶数据的搬迁，但是每次至多也只能搬迁2个桶，这种渐进式的搬迁方式能缓解扩容时的性能压力。

10. 扩容过程是怎么样的？

   ​	当元素在散列表中的分布太密集或太稀疏都会触发扩容（增量扩容和等量扩容）。扩容主要分两步：

   1. 分配新的bucket数组内存以及对一些变量做处理，例如将`oldbuckets`指向原来的`buckets`等等
   2. 在插入和删除操作中执行一次搬迁工作，每次搬迁至多搬迁二个桶，至少搬迁一个桶

11. 增量扩容和等量扩容有什么区别？

    ​	增量扩容和等量扩容最大的区别就是：增量扩容会将桶数量变成原来的两倍，因此旧桶上的元素会分裂到扩容后的2个桶中，所以在搬迁旧桶的元素时，可能需要再计算key的hash值，判断它应该分配到分裂后的哪个桶中。相对应的，等量扩容后则还是原来的桶数量，旧桶和新桶是一对一的关系。

12. 赋值过程是怎么样的？

13. 遍历过程是怎么样的？

    1. 初始化一个迭代器，维护遍历状态信息，例如当前遍历的bucket和初始化迭代器时的map快照信息等
    2. 随机计算一个遍历的起始bucket以及遍历每个槽位时的偏移值
    3. 遍历bucket顺序从起始bucket到它的溢出桶再到下一个bucket，直到又回到起始bucket；而遍历槽位的顺序是从每个bucket的偏移值（（2）中计算的）开始的
    4. 当map处于扩容状态时，在遍历一个bucket时，需要去对应的旧桶中，找到属于该bucket的值

14. 可以对map的元素取地址吗？

    ​	不能，即使通过`unsafe.Pointer`等方式取到地址，如果发生扩容，对应的值的地址就会改变

15. 可以边遍历边删除吗？

    ​	检测到读写并发会发生panic。可以单协程在一个遍历块中进行删除操作

16. 如何比较两个map相等？

    ​	map 不支持 == 操作，会发生编译错误。因此只能通过遍历的去比较 map 的长度 以及 value 的深度



# 参考资料

1. [Go-Questions](https://github.com/changkun/Go-Questions)



