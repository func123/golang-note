分析完调度器的初始化后，接下来开始初始化main gorountine

```go
CALL	runtime·schedinit(SB)	// 调度初始化,完成g0、p、m0、thread 的关联
// 继续往下看
// create a new goroutine to start program
// 将用户代码main函数放入到AX寄存器中
MOVQ	$runtime·mainPC(SB), AX		// entry
PUSHQ	AX			// 调用newproc的第二个参数 
PUSHQ	$0			// arg size  ，第一个参数是main函数的参数大小
// 创建main gorountine用来运行AX中的main方法 
// 并且将创建的main gorountine放入到allp[0]的可运行队列中
// 创建新的m 与 allp[1] 绑定
CALL	runtime·newproc(SB) 
POPQ	AX
POPQ	AX
```

​	准备好main函数和参数，开始初始化main gorountine

```go
// Create a new g running fn with siz bytes of arguments.
// Put it on the queue of g's waiting to run.
// The compiler turns a go statement into a call to this.
// Cannot split the stack because it assumes that the arguments
// are available sequentially after &fn; they would not be
// copied if a stack split occurred.
//go:nosplit
func newproc(siz int32, fn *funcval) {	// size : 函数fn参数的大小  ， // fn：调用的函数
	argp := add(unsafe.Pointer(&fn), sys.PtrSize)  // 参数开始的位置
	gp := getg() // 这里是 g0
	pc := getcallerpc() 
	systemstack(func() { // systemstack 切换到g0栈运行函数，然后再切换回来，这里本身就在g0栈，因此没有切换
		newproc1(fn, (*uint8)(argp), siz, gp, pc)
	})
}

// Create a new g running fn with narg bytes of arguments starting
// at argp. callerpc is the address of the go statement that created
// this. The new g is put on the queue of g's waiting to run.
func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) {
	_g_ := getg()

	if fn == nil {
		_g_.m.throwing = -1 // do not dump full stacks
		throw("go of nil func value")
	}
    // 锁住当前g对应的m，即m0
	acquirem() // disable preemption because it can be holding p in a local var
	siz := narg
	siz = (siz + 7) &^ 7

	// We could allocate a larger initial stack if necessary.
	// Not worth it: this is almost always an error.
	// 4*sizeof(uintreg): extra space added below
	// sizeof(uintreg): caller's LR (arm) or return address (x86, in gostartcall).
	if siz >= _StackMin-4*sys.RegSize-sys.RegSize {
		throw("newproc: function arguments too large for new goroutine")
	}

	_p_ := _g_.m.p.ptr()  // 获取p，allp[0]
    // 从 p 中 获取空闲的g，因为p中没有任何g，这里返回nil，
	newg := gfget(_p_)	
	if newg == nil {
        // 分配一个栈大小为 2K  的 g，初始化g的栈成员：stack、stackguard0、stackguard1
		newg = malg(_StackMin) // _StackMin = 2048，即2K 
		casgstatus(newg, _Gidle, _Gdead)	// 更改g的状态为 _Gdead
        // 将创建的g放入到全局变量allgs中，以及更新allglen的值
		allgadd(newg) // publishes with a g->status of Gdead so GC scanner doesn't look at uninitialized stack.
	}
	if newg.stack.hi == 0 {
		throw("newproc1: newg missing stack")
	}

	if readgstatus(newg) != _Gdead {
		throw("newproc1: new g is not Gdead")
	}

	totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize // extra space in case of reads slightly beyond frame
	totalSize += -totalSize & (sys.SpAlign - 1)                  // align to spAlign
	sp := newg.stack.hi - totalSize
	spArg := sp
	if usesLR {
		// caller's LR
		*(*uintptr)(unsafe.Pointer(sp)) = 0
		prepGoExitFrame(sp)
		spArg += sys.MinFrameSize
	}
    // main函数参数大小为0 ,跳过这个条件代码块
	if narg > 0 {
		memmove(unsafe.Pointer(spArg), unsafe.Pointer(argp), uintptr(narg))
		// This is a stack-to-stack copy. If write barriers
		// are enabled and the source stack is grey (the
		// destination is always black), then perform a
		// barrier copy. We do this *after* the memmove
		// because the destination stack may have garbage on
		// it.
		if writeBarrier.needed && !_g_.m.curg.gcscandone {
			f := findfunc(fn.fn)
			stkmap := (*stackmap)(funcdata(f, _FUNCDATA_ArgsPointerMaps))
			if stkmap.nbit > 0 {
				// We're in the prologue, so it's always stack map index 0.
				bv := stackmapdata(stkmap, 0)
				bulkBarrierBitmap(spArg, spArg, uintptr(bv.n)*sys.PtrSize, 0, bv.bytedata)
			}
		}
	}
	// 清空main g的调度信息sched：g运行时的sp等寄存器
	memclrNoHeapPointers(unsafe.Pointer(&newg.sched), unsafe.Sizeof(newg.sched))
    // 以下初始化 main g的调度信息
    // 更新main g的栈指针sp（栈顶：低地址）
	newg.sched.sp = sp
	newg.stktopsp = sp
    // 更新main g的pc 为 goexit的地址 + 1 ，即当前pc值，那么即将运行的下条指令就是调用goexit 
	newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function
 	// 更新 sched.g
	newg.sched.g = guintptr(unsafe.Pointer(newg))
    // pc的下条指令是调用goexit，这里实现了类似汇编CALL的效果，将pc下条指令“调用goexit” 入栈，更改pc 为 main 函数的地址，实现在执行goexit前调用 main 函数的效果，这样当main函数执行完后就会执行goexit。同时也更新sched.ctxt 
	gostartcallfn(&newg.sched, fn)
	newg.gopc = callerpc
	newg.ancestors = saveAncestors(callergp)
    // main 函数的第一条指令地址
	newg.startpc = fn.fn
	if _g_.m.curg != nil {
		newg.labels = _g_.m.curg.labels
	}
	if isSystemGoroutine(newg, false) {
		atomic.Xadd(&sched.ngsys, +1)
	}
	newg.gcscanvalid = false
    // 更新main g状态为_Grunnable
	casgstatus(newg, _Gdead, _Grunnable)

	if _p_.goidcache == _p_.goidcacheend {
		// Sched.goidgen is the last allocated id,
		// this batch must be [sched.goidgen+1, sched.goidgen+GoidCacheBatch].
		// At startup sched.goidgen=0, so main goroutine receives goid=1.
		_p_.goidcache = atomic.Xadd64(&sched.goidgen, _GoidCacheBatch) // _GoidCacheBatch=16
		_p_.goidcache -= _GoidCacheBatch - 1  // 1 
		_p_.goidcacheend = _p_.goidcache + _GoidCacheBatch // 17 
	}
	newg.goid = int64(_p_.goidcache) // 1 
	_p_.goidcache++ // 2 
	if raceenabled {
		newg.racectx = racegostart(callerpc)
	}
	if trace.enabled {
		traceGoCreate(newg, newg.startpc)
	}
    // 将 main g 放到 p 的可运行队列中，因为是true，所以放到对应nextRun的槽位，否则是放到队列尾部中
	runqput(_p_, newg, true)
	// sched.npidle = nproc - 1 ,sched.nmspinning = 0 ,mainStarted=false
	if atomic.Load(&sched.npidle) != 0 && atomic.Load(&sched.nmspinning) == 0 && mainStarted {
        // 唤醒一个p并且绑定新建的m去执行main g
		wakep()
	}
	releasem(_g_.m)
}

```

​		初始化main gorountine，准备好运行时的调度信息（sp，pc），放进allp[0]的可运行队列中，创建并初始化新的m，并且与allp[1]绑定

```go
// Tries to add one more P to execute G's.
// Called when a G is made runnable (newproc, ready).
func wakep() {
	// be conservative about spinning threads
	if !atomic.Cas(&sched.nmspinning, 0, 1) { // 在其他地方已经wakep，所以返回
		return
	}
	startm(nil, true)
}

// Schedules some M to run the p (creates an M if necessary).
// If p==nil, tries to get an idle P, if no idle P's does nothing.
// May run with m.p==nil, so write barriers are not allowed.
// If spinning is set, the caller has incremented nmspinning and startm will
// either decrement nmspinning or set m.spinning in the newly started M.
//go:nowritebarrierrec
func startm(_p_ *p, spinning bool) {
	lock(&sched.lock)	// 因为需要从全局变量schedt中找p和m，因此要加锁
	if _p_ == nil { 
		_p_ = pidleget() //从调度器schedt中取出空闲的p，并更新相关值
		······
	}
	mp := mget()	// 从调度器schedt取空闲的m，但是此时没有空闲的m，返回 mp = nil
	unlock(&sched.lock)
	if mp == nil {
		var fn func()
		if spinning { 	// spinning = true
			// The caller incremented nmspinning, so set m.spinning in the new M.
			fn = mspinning  // fn：修改当前线程绑定的m：m.spinning = true
		}
		newm(fn, _p_)
		return
	}
	if mp.spinning {
		throw("startm: m is spinning")
	}
	if mp.nextp != 0 {
		throw("startm: m has p")
	}
	if spinning && !runqempty(_p_) {
		throw("startm: p has runnable gs")
	}
	// The caller incremented nmspinning, so set m.spinning in the new M.
	mp.spinning = spinning
	mp.nextp.set(_p_)
	notewakeup(&mp.park)
}


// Create a new m. It will start off with a call to fn, or else the scheduler.
// fn needs to be static and not a heap allocated closure.
// May run with m.p==nil, so write barriers are not allowed.
//go:nowritebarrierrec
func newm(fn func(), _p_ *p) {
    // 创建一个未绑定p的m，并且进行初始化，加入allm链表中，设置m.mstartfn = 修改当前线程绑定的m：m.spinning = true
	mp := allocm(_p_, fn)
    // mp.nextp = allp[1]
	mp.nextp.set(_p_)
	mp.sigmask = initSigmask
	if gp := getg(); gp != nil && gp.m != nil && (gp.m.lockedExt != 0 || gp.m.incgo) && GOOS != "plan9" {
		// We're on a locked M or a thread that may have been
		// started by C. The kernel state of this thread may
		// be strange (the user may have locked it for that
		// purpose). We don't want to clone that into another
		// thread. Instead, ask a known-good thread to create
		// the thread for us.
		//
		// This is disabled on Plan 9. See golang.org/issue/22227.
		//
		// TODO: This may be unnecessary on Windows, which
		// doesn't model thread creation off fork.
		lock(&newmHandoff.lock)
		if newmHandoff.haveTemplateThread == 0 {
			throw("on a locked thread with no template thread")
		}
		mp.schedlink = newmHandoff.newm
		newmHandoff.newm.set(mp)
		if newmHandoff.waiting {
			newmHandoff.waiting = false
			notewakeup(&newmHandoff.wake)
		}
		unlock(&newmHandoff.lock)
		return
	}
	newm1(mp)
}

// Allocate a new m unassociated with any thread.
// Can use p for allocation context if needed.
// fn is recorded as the new m's m.mstartfn.
//
// This function is allowed to have write barriers even if the caller
// isn't because it borrows _p_.
//
//go:yeswritebarrierrec
func allocm(_p_ *p, fn func()) *m {
	_g_ := getg() // 获取当前g，g0
    // 将 m0 加锁
	acquirem() // disable GC because it can be called from sysmon

	······

	mp := new(m)
	mp.mstartfn = fn // fn：修改当前线程绑定的m：m.spinning = true
	mcommoninit(mp)	// 跟初始化m0一样，将mp 加入到链表allm中，mp的上一个m就是m0

	// In case of cgo or Solaris or illumos or Darwin, pthread_create will make us a stack.
	// Windows and Plan 9 will layout sched stack on OS stack.
	if iscgo || GOOS == "solaris" || GOOS == "illumos" || GOOS == "windows" || GOOS == "plan9" || GOOS == "darwin" {
		mp.g0 = malg(-1)	//  创建 new g
	} else {
		mp.g0 = malg(8192 * sys.StackGuardMultiplier)
	}
	mp.g0.m = mp	 // 这个g0 不是 主线程的g0，新分配的g

	if _p_ == _g_.m.p.ptr() { // _p_  = allp[1] ，  _g_.m.p.ptr() == allp[0]
		releasep()
	}
    // 将 m0 解锁
	releasem(_g_.m)

	return mp
}
```

