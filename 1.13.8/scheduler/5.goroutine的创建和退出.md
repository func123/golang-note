# g的创建	

在看非main g的退出前，先看下它的创建

```go
func main() {
	go func() {
		for {
			fmt.Println()
		}
	}()
	time.Sleep(time.Second * 5)
}

// 终端执行：go tool compile -N -l -S main.go
// 找到对应的汇编代码
MOVL    $0, (SP)	// 将gorountine执行的函数参数大小放到SP对应地址上，这里是 0 
PCDATA  $0, $1	
LEAQ    "".main.func1·f(SB), AX		
PCDATA  $0, $0
MOVQ    AX, 8(SP)	// 设置函数地址
CALL    runtime.newproc(SB)	
```

​	从上面可以看出g的创建会调用`runtime.newproc`函数，接下来具体看一下

```go
// Create a new g running fn with siz bytes of arguments.
// Put it on the queue of g's waiting to run.
// The compiler turns a go statement into a call to this.
// Cannot split the stack because it assumes that the arguments
// are available sequentially after &fn; they would not be
// copied if a stack split occurred.
//go:nosplit
func newproc(siz int32, fn *funcval) {
	argp := add(unsafe.Pointer(&fn), sys.PtrSize)
	gp := getg()	// main g 
	pc := getcallerpc()	// main g 中执行go关键字的下一条指令
	systemstack(func() {	// systemstack切换到go栈执行
		newproc1(fn, (*uint8)(argp), siz, gp, pc)
	})
}

// 在 g0 栈中执行
// Create a new g running fn with narg bytes of arguments starting
// at argp. callerpc is the address of the go statement that created
// this. The new g is put on the queue of g's waiting to run.
// fn： go关键字执行的函数的封装
// argp：参数的起始位置 ， narg：参数的长度
// callergp：调用者的g，这里是main g
// callerpc：callergp的下一条pc，这里是main g调用go关键字的下一条指令
func newproc1(fn *funcval, argp *uint8, narg int32, callergp *g, callerpc uintptr) {
	_g_ := getg()	// g0

	······

	_p_ := _g_.m.p.ptr()	// main g 绑定的m0，m0绑定的p 是 allp[0]
	newg := gfget(_p_)	// 从p的空闲g队列中和全局的空闲g队列中获取g，这里是nil
	if newg == nil {	// 创建2k的新的g，并且初始化stackguard0、stackguard1
		newg = malg(_StackMin)
		casgstatus(newg, _Gidle, _Gdead) // 设置初始状态为_Gdead
        // 放入到全局的g数组allgs中，并且更新allglen
		allgadd(newg) // publishes with a g->status of Gdead so GC scanner doesn't look at uninitialized stack.
	}
    
	······
    // g运行的函数带参数，因此将参数复制到g的栈上
	if narg > 0 {
		memmove(unsafe.Pointer(spArg), unsafe.Pointer(argp), uintptr(narg))
		// This is a stack-to-stack copy. If write barriers
		// are enabled and the source stack is grey (the
		// destination is always black), then perform a
		// barrier copy. We do this *after* the memmove
		// because the destination stack may have garbage on
		// it.
		if writeBarrier.needed && !_g_.m.curg.gcscandone {
			f := findfunc(fn.fn)
			stkmap := (*stackmap)(funcdata(f, _FUNCDATA_ArgsPointerMaps))
			if stkmap.nbit > 0 {
				// We're in the prologue, so it's always stack map index 0.
				bv := stackmapdata(stkmap, 0)
				bulkBarrierBitmap(spArg, spArg, uintptr(bv.n)*sys.PtrSize, 0, bv.bytedata)
			}
		}
	}
	// 清除g的调度信息
	memclrNoHeapPointers(unsafe.Pointer(&newg.sched), unsafe.Sizeof(newg.sched))
    // 设置g的调度信息
	newg.sched.sp = sp
	newg.stktopsp = sp
    // 设置g的退出函数，伪造成在goexit中通过CALL调用fn一样
	newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function
	newg.sched.g = guintptr(unsafe.Pointer(newg))
	gostartcallfn(&newg.sched, fn)
	newg.gopc = callerpc
	newg.ancestors = saveAncestors(callergp)
	newg.startpc = fn.fn
	if _g_.m.curg != nil {
		newg.labels = _g_.m.curg.labels
	}
	if isSystemGoroutine(newg, false) {
		atomic.Xadd(&sched.ngsys, +1)
	}
	newg.gcscanvalid = false
    // 设置完调度信息后，将状态改成 _Grunnable
	casgstatus(newg, _Gdead, _Grunnable)

	······
    
	newg.goid = int64(_p_.goidcache)
	_p_.goidcache++
    
	······
    // 将g放入到p的可运行队列中，这里是allp[0]
	runqput(_p_, newg, true)
    // 此时：sched.npidle = nproc - 1 ,sched.nmspinning = 0 ,mainStarted=true(在创建main g的时被设置成true)
	if atomic.Load(&sched.npidle) != 0 && atomic.Load(&sched.nmspinning) == 0 && mainStarted {
		wakep()
	}
	releasem(_g_.m)
}
```

​	main g之后的第一个g的初始化跟main g大同小异，同样是放入allp[0]这个p中，但是这次会执行`wakep`

```go
// Tries to add one more P to execute G's.
// Called when a G is made runnable (newproc, ready).
func wakep() {
	// be conservative about spinning threads
   	// sched.nmspinning  = 1 
	if !atomic.Cas(&sched.nmspinning, 0, 1) {
		return
	}
	startm(nil, true)
}


// Schedules some M to run the p (creates an M if necessary).
// If p==nil, tries to get an idle P, if no idle P's does nothing.
// May run with m.p==nil, so write barriers are not allowed.
// If spinning is set, the caller has incremented nmspinning and startm will
// either decrement nmspinning or set m.spinning in the newly started M.
//go:nowritebarrierrec
func startm(_p_ *p, spinning bool) {
	lock(&sched.lock)
	if _p_ == nil {
		_p_ = pidleget()	// 从空闲p中取p，此前只有一个allp[0]在运行，所以此时有空闲的p
		if _p_ == nil {
			unlock(&sched.lock)
			if spinning {
				// The caller incremented nmspinning, but there are no idle Ps,
				// so it's okay to just undo the increment and give up.
				if int32(atomic.Xadd(&sched.nmspinning, -1)) < 0 {
					throw("startm: negative nmspinning")
				}
			}
			return
		}
	}
	mp := mget()	// 此前只创建了m0，没有空闲的了，因此mp=nil
	unlock(&sched.lock)
	if mp == nil {
		var fn func()
		if spinning {	// true
			// The caller incremented nmspinning, so set m.spinning in the new M.
			fn = mspinning	// mspinning作用是获取线程绑定的g.m.spinning = true
		}
		newm(fn, _p_)
		return
	}
	······
    // 如果有可以复用的m，则更改自旋状态为true并且绑定上p，让它继续动起来
	// The caller incremented nmspinning, so set m.spinning in the new M.
	mp.spinning = spinning
	mp.nextp.set(_p_)
	notewakeup(&mp.park)
}


```

​		首先是找到空闲的p，如果没有就返回了。之后开始找到可用的m唤醒后运行，没有则会创建新的m，下面看没有可用m的情况

```go
// Create a new m. It will start off with a call to fn, or else the scheduler.
// fn needs to be static and not a heap allocated closure.
// May run with m.p==nil, so write barriers are not allowed.
//go:nowritebarrierrec
func newm(fn func(), _p_ *p) {
	mp := allocm(_p_, fn)	// 创建一个m并且初始化状态
	mp.nextp.set(_p_)	// 将mp和p绑定，这里的p是allp[1]
	mp.sigmask = initSigmask
	······
	newm1(mp)
}

func newm1(mp *m) {
	······
	execLock.rlock() // Prevent process clone.
	newosproc(mp)
	execLock.runlock()
}

// os_linux.go/newosproc
// May run with m.p==nil, so write barriers are not allowed.
//go:nowritebarrier
func newosproc(mp *m) {
	stk := unsafe.Pointer(mp.g0.stack.hi)
	······
    // 创建子线程
	ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0), unsafe.Pointer(funcPC(mstart)))
	······
}


// int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
TEXT runtime·clone(SB),NOSPLIT,$0	
	MOVL	flags+0(FP), DI	// 准备系统调用参数
	MOVQ	stk+8(FP), SI
	MOVQ	$0, DX
	MOVQ	$0, R10

	// Copy mp, gp, fn off parent stack for use by child.
	// Careful: Linux system call clobbers CX and R11.
	MOVQ	mp+16(FP), R8
	MOVQ	gp+24(FP), R9
	MOVQ	fn+32(FP), R12

	MOVL	$SYS_clone, AX	
	SYSCALL					// 进行系统调用，创建子线程

	// In parent, return.	// 返回的新旧线程都从这里执行，根据系统调用返回值的不同分别执行后续代码
	CMPQ	AX, $0
	JEQ	3(PC)		
	MOVL	AX, ret+40(FP)	
	RET				// 旧线程返回

	// In child, on new stack.	// 新线程继续执行
	MOVQ	SI, SP

	// If g or m are nil, skip Go-related setup.
	CMPQ	R8, $0    // m	//父线程寄存器的值被复制到子线程上了，所以子线程可以拿到m和g
	JEQ	nog
	CMPQ	R9, $0    // g
	JEQ	nog

	// Initialize m->procid to Linux tid
	MOVL	$SYS_gettid, AX	// 获取线程id
	SYSCALL
	MOVQ	AX, m_procid(R8)	// 设置m.procid=线程id

	// Set FS to point at m->tls.
	LEAQ	m_tls(R8), DI		// 设置新线程的TLS
	CALL	runtime·settls(SB)

	// In child, set up new stack
	get_tls(CX)
	MOVQ	R8, g_m(R9)		// g.m = m 
	MOVQ	R9, g(CX)	
	CALL	runtime·stackcheck(SB)

nog:
	// Call fn
	CALL	R12	 // 调用 mstart
```

​	创建m后会进行相关初始化，然后进行系统调用创建子线程，系统调用返回后会多一个系统线程，新的线程和旧线程都是从系统调用返回处继续执行代码。这里是怎么分辨新旧线程呢？这里可以通过系统调用的返回值进行判断，系统调用的返回值如果是0则表示这是子线程，不为0则表示这个是父线程。经过类似`if 父线程 ｛执行父线程代码} else {执行子线程代码}`的处理，就能让新旧线程各自执行各自的代码。如果是父线程，创建完子线程后就返回了，而子线程会继续进行相关初始化，包括设置新线程的线程本地存储，将新建的m对象和系统线程绑定起来，最后调用 `mstart`函数，也是新线程的入口函数，但因为不是m0，所以会执行`mstartfn`函数，更改m的`spinning`状态，使之进行自旋状态，再调用`schedule`函数，开始进行循环调度。此时因为绑定的p（allp[1]）中没有待运行的g，因此会从allp[0]中拿到g来运行。

# g的退出

非main g退出后将返回到`runtime·goexit`中继续执行，下面继续来看

```go
// The top-most function running on a goroutine
// returns to goexit+PCQuantum.
TEXT runtime·goexit(SB),NOSPLIT,$0-0
	BYTE	$0x90	// NOP
	CALL	runtime·goexit1(SB)	// does not return
	// traceback from goexit1 must hit code range of goexit
	BYTE	$0x90	// NOP

// runtime/proc.go
// Finishes execution of the current goroutine.
func goexit1() {
	if raceenabled {
		racegoend()
	}
	if trace.enabled {
		traceGoEnd()
	}
	mcall(goexit0)
}
```

​	goroutine在退出后一路执行到`mcall`，这里作用主要是保存g的调度信息，将g0放入到线程本地存储，切换到g0栈

```go
// func mcall(fn func(*g))
// Switch to m->g0's stack, call fn(g).
// Fn must never return. It should gogo(&g->sched)
// to keep running g.
TEXT runtime·mcall(SB), NOSPLIT, $0-8
	MOVQ	fn+0(FP), DI	// 将参数放到DI寄存器上
	// 保存g的调度信息
	get_tls(CX)			
	MOVQ	g(CX), AX	// save state in g->sched 	// 将g放入AX寄存器
	MOVQ	0(SP), BX	// caller's PC	
	MOVQ	BX, (g_sched+gobuf_pc)(AX)		//保存g的调度信息到g.gobuf中
	LEAQ	fn+0(FP), BX	// caller's SP
	MOVQ	BX, (g_sched+gobuf_sp)(AX)
	MOVQ	AX, (g_sched+gobuf_g)(AX)
	MOVQ	BP, (g_sched+gobuf_bp)(AX)

	// switch to m->g0 & its stack, call fn	
	// 找到g0
	MOVQ	g(CX), BX	// BX = g
	MOVQ	g_m(BX), BX	// BX = g.m
	MOVQ	m_g0(BX), SI	// SI = g.m.g0
	// 错误退出保护
	CMPQ	SI, AX	// if g == m->g0 call badmcall
	JNE	3(PC)
	MOVQ	$runtime·badmcall(SB), AX
	JMP	AX
	// 恢复g0的调度信息到对应寄存器，从g栈切换到g0栈
	MOVQ	SI, g(CX)	// g = m->g0  // 将g0设置到线程本地存储中
	MOVQ	(g_sched+gobuf_sp)(SI), SP	// sp = m->g0->sched.sp 
	PUSHQ	AX			// AX=g，这里入栈作为后面调用goexit0函数的参数
	MOVQ	DI, DX		// DX = goexit0（结构体funcval实例对象的指针）
	MOVQ	0(DI), DI	// goexit0
	CALL	DI		// 调用 goexit0 函数
	POPQ	AX
	MOVQ	$runtime·badmcall2(SB), AX
	JMP	AX
	RET
```

​	`mcall`函数主要做了三件事：

1. 将g的调度信息保存起来
2. 通过`g.m.g0`找到g0，放入到线程本地存储中，并且恢复g0的调度信息到寄存器上，完成g-->g0栈的切换
3. 在g0栈上调用 `goexit0`函数

做完这些事情，接下来就在g0栈上执行`goexit0`函数

```go
// goexit continuation on g0.
func goexit0(gp *g) {	// gp = g 
	_g_ := getg()	// 获取g0

	casgstatus(gp, _Grunning, _Gdead)	// 设置g的状态为_Gdead
	if isSystemGoroutine(gp, false) {
		atomic.Xadd(&sched.ngsys, -1)
	}
    // 清除g的相关状态
	gp.m = nil	// 将 g 和 m 解绑
	locked := gp.lockedm != 0
	gp.lockedm = 0
	_g_.m.lockedg = 0
	gp.paniconfault = false
	gp._defer = nil // should be true already but just in case.
	gp._panic = nil // non-nil for Goexit during panic. points at stack-allocated data.
	gp.writebuf = nil
	gp.waitreason = 0
	gp.param = nil
	gp.labels = nil
	gp.timer = nil

	······

	// Note that gp's stack scan is now "valid" because it has no
	// stack.
	gp.gcscanvalid = true
	dropg()

	······
    
    // 将 g 放入到p的空闲队列中，便于重用
	gfput(_g_.m.p.ptr(), gp)
    
	······
    
	schedule()
}
```

​	g的生命周期至此就结束了：`g()->goexit()->goexit1()->mcall()`，在`macll`中切换到g0栈，之后通过调用`goexit0`函数清除g的相关状态信息，并且与m解绑后放入到p的空闲队列中以便下次被重用。最后通过调用`schedule`开始新一轮的调度